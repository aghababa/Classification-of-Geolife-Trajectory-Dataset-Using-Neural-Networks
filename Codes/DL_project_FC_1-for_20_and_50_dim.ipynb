{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V-xJxlvIlCjB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "from scipy import linalg as LA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3Baay7UJlCjG"
   },
   "outputs": [],
   "source": [
    "float = np.vectorize(float)\n",
    "\n",
    "def read_file(file_name):\n",
    "    data = []\n",
    "    with open(file_name, \"r\") as f:\n",
    "        for line in f:\n",
    "            item = line.strip().split(\",\")\n",
    "            data.append(float(item))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XD6GckUylCjI"
   },
   "outputs": [],
   "source": [
    "#I = glob.glob('DL Project/20-dim data (41) representation sigma=0.3/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/20-dim data (41) representation old distamce/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/50-dim data (41) representation sigma=0.25/*.csv', recursive=True)\n",
    "I = glob.glob('DL Project/50-dim data (41) representation sigma=1000/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/50-dim data (41) representation old distamce/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/250-dim data (41) representation sigma=1/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/250-dim data (41) representation old distamce/*.csv', recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = len(I)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "abqsEqTalCjK"
   },
   "outputs": [],
   "source": [
    "data_embed = [0] * r\n",
    "\n",
    "for i in range(r):\n",
    "    data_embed[i] = [len(np.array(read_file(I[i]))), np.array(read_file(I[i]))]\n",
    "\n",
    "data_embed = np.array(data_embed)\n",
    "#data_embed = data_embed[data_embed[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [0] * r\n",
    "X_test = [0] * r\n",
    "y_train = [0] * r\n",
    "y_test = [0] * r\n",
    "\n",
    "for i in range(r):\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(np.array(data_embed[i][1]), \n",
    "                                                                np.ones(len(data_embed[i][1])), \n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(r):\n",
    "    X_train[i] = torch.tensor(X_train[i])\n",
    "    X_test[i] = torch.tensor(X_test[i])\n",
    "    y_train[i] = torch.tensor(y_train[i])\n",
    "    y_test[i] = torch.tensor(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.3486e-05, -1.6719e-05, -1.3998e-04, -2.0105e-04, -2.2536e-04,\n",
       "        -2.6060e-04, -2.1736e-04, -1.5355e-04, -3.9396e-05, -5.4392e-06,\n",
       "        -3.5594e-05, -9.4164e-05, -1.4461e-04, -1.5219e-04, -7.8480e-05,\n",
       "        -6.2985e-05, -1.3133e-04, -3.1368e-04, -3.1661e-04, -4.2472e-04,\n",
       "        -4.0890e-04, -2.9497e-04, -2.5576e-04, -1.2452e-04, -2.2038e-04,\n",
       "         1.3053e-04,  3.8230e-04,  3.0821e-04,  5.7134e-04,  2.6316e-04,\n",
       "         2.6310e-05, -1.1681e-04, -3.4364e-04, -6.2630e-04, -6.3422e-04,\n",
       "        -3.6071e-04,  6.8906e-05, -3.4059e-04, -6.9094e-04, -1.0120e-03,\n",
       "        -1.3365e-03, -1.4892e-03, -1.7201e-03, -5.7177e-04,  2.8795e-04,\n",
       "        -3.8456e-04, -1.5549e-04, -1.5005e-04, -4.7357e-04,  7.6625e-05],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data_embed[:,0]\n",
    "A = np.sort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 101 106 108 112 113 120 133 144 146 147 148 150 150 154 160 167 173\n",
      " 182 196 196 207 215 226 260 275 295 318 371 382 389 394 407 423 544 583\n",
      " 678 747 800 2014 2124]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Layer Fully Connected Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Start_time = time.time()\n",
    "\n",
    "mean_train_error = 0\n",
    "mean_test_error = 0\n",
    "var_test_error = 0\n",
    "\n",
    "lr_decay = 0.7\n",
    "num_trials = 1\n",
    "learning_rate = 1e-2\n",
    "Num_updates = 15000\n",
    "losses = torch.zeros(num_trials, r-9, Num_updates)\n",
    "\n",
    "for s in range(num_trials):\n",
    "\n",
    "    error_train_list_all = []\n",
    "    error_test_list_all = []\n",
    "\n",
    "    Start_time_2 = time.time()\n",
    "\n",
    "    for i in range(r-9): \n",
    "\n",
    "        x = torch.cat((X_train[i], X_train[i+1], X_train[i+2], X_train[i+3], \n",
    "                       X_train[i+4],X_train[i+5], X_train[i+6], X_train[i+7],\n",
    "                       X_train[i+8], X_train[i+9]), 0).float()\n",
    "        y = torch.cat((0 * y_train[i], y_train[i+1], 2 * y_train[i+2], 3 * y_train[i+3],\n",
    "                       4 * y_train[i+4], 5 * y_train[i+5], 6 * y_train[i+6], 7* y_train[i+7],\n",
    "                       8 * y_train[i+8], 9 * y_train[i+9]), 0).long()\n",
    "\n",
    "        D_in = len(x[0]) # D_in is input dimension\n",
    "        H = 200 # H is the dimension of hidden layer\n",
    "        D_out = 10 # D_out is output dimension\n",
    "\n",
    "        model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(D_in, H),\n",
    "                                    torch.nn.LeakyReLU(0.01),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    #torch.nn.Tanh(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H, D_out)\n",
    "                                    )\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for t in range(Num_updates):\n",
    "            y_pred = model(x) # of shape (N,D_out)\n",
    "            #print(torch.argmax(y_pred, 1))\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            losses[s, i, t] = loss\n",
    "\n",
    "            #if t % 1000 == 0:\n",
    "            #    print(t, loss.item())\n",
    "                \n",
    "            if (t+1) % 400 == 0:\n",
    "                optimizer.param_groups[0]['lr'] = lr_decay * learning_rate\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "\n",
    "            optimizer.step()  # Calling the step function on the Optimizer \n",
    "\n",
    "        X = torch.cat((X_test[i], X_test[i+1], X_test[i+2], X_test[i+3], \n",
    "                       X_test[i+4],X_test[i+5], X_test[i+6], X_test[i+7],\n",
    "                       X_test[i+8], X_test[i+9]), 0).float()\n",
    "        Y = torch.cat((0 * y_test[i], y_test[i+1], 2 * y_test[i+2], 3 * y_test[i+3],\n",
    "                       4 * y_test[i+4], 5 * y_test[i+5], 6 * y_test[i+6], 7* y_test[i+7],\n",
    "                       8 * y_test[i+8], 9 * y_test[i+9]), 0).long()\n",
    "        \n",
    "        Y_pred = model(X)\n",
    "        \n",
    "        error_train_list_all.append((torch.argmax(y_pred, 1) != y).sum().float()/len(y))\n",
    "        error_test_list_all.append((torch.argmax(Y_pred, 1) != Y).sum().float()/len(Y))\n",
    "\n",
    "    mean_train_error += np.mean(error_train_list_all)\n",
    "    mean_test_error += np.mean(error_test_list_all)\n",
    "    var_test_error += np.var(error_test_list_all)\n",
    "\n",
    "mean_train_error /= num_trials\n",
    "mean_test_error /= num_trials\n",
    "var_test_error /= num_trials\n",
    "\n",
    "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=20$, $\\sigma=0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, sigma = 0.3, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.5 , Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Num_classes</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FC 1-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier  Num_classes  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  FC 1-Layer           10         200       None            0.1   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.2352      0.4007           0.005  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'sigma = 0.3,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"FC 1-Layer\", 10, H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Num_classes', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Distance, $|Q|=20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.9 , Number of Updates =  5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Num_classes</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FC 1-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier  Num_classes  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  FC 1-Layer           10          20       None          0.007   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.3246      0.3275          0.0029  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"FC 1-Layer\", 10, H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Num_classes', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=50$, $\\sigma=0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, sigma = 0.25, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.9 , Number of Updates =  500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Num_classes</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FC 1-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.02</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier  Num_classes  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  FC 1-Layer           10          50       None           0.02   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.0493      0.4899          0.0069  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'sigma = 0.25,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"FC 1-Layer\", 10, H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Num_classes', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=50$, $\\sigma=1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, sigma = 1000, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.7 , Number of Updates =  15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Num_classes</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Num_classes  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer           10         200       None           0.01   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.2111      0.5367          0.0057  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'sigma = 1000,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", 10, H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Num_classes', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Distance, $|Q|=50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.4 , Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer         500       None           0.01   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.1422       0.192          0.0017  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'Old Distance,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Start_time = time.time()\n",
    "\n",
    "mean_train_error = 0\n",
    "mean_test_error = 0\n",
    "var_test_error = 0\n",
    "\n",
    "lr_decay = 0.9\n",
    "num_trials = 1\n",
    "learning_rate = 5e-3\n",
    "Num_updates = 1000\n",
    "losses = torch.zeros(num_trials, r-1, Num_updates)\n",
    "\n",
    "for s in range(num_trials):\n",
    "    \n",
    "    X_train_labeled = [0] * r\n",
    "    X_test_labeled = [0] * r\n",
    "    error_train_list_all = []\n",
    "    error_test_list_all = []\n",
    "\n",
    "    Start_time_2 = time.time()\n",
    "\n",
    "    for i in range(r-1): #31-34\n",
    "        j = i+1\n",
    "\n",
    "        x = torch.cat((X_train[i], X_train[j]), 0).float()\n",
    "        y = torch.cat((y_train[i], \n",
    "                       torch.zeros(y_train[j].size(), dtype=torch.double)), 0).long()\n",
    "        \n",
    "        #mean = torch.mean(x, dim=0)\n",
    "        #std = torch.std(x, dim=0)\n",
    "        #x = (x - mean)/std\n",
    "\n",
    "        N = len(x) # N is batch size\n",
    "        D_in = len(x[0]) # D_in is input dimension\n",
    "        H = 500 # H is the dimension of hidden layer\n",
    "        D_out = 2 # D_out is output dimension\n",
    "        q = 0.5\n",
    "\n",
    "        model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(D_in, H),\n",
    "                                    torch.nn.LeakyReLU(0.01),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    #torch.nn.Tanh(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H, D_out)\n",
    "                                    )\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for t in range(Num_updates):\n",
    "            y_pred = model(x) # of shape (N,D_out)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            losses[s, i, t] = loss\n",
    "\n",
    "            #if t % 1000 == 0:\n",
    "            #    print(t, loss.item())\n",
    "                \n",
    "            if (t+1) % 1000 == 0:\n",
    "                optimizer.param_groups[0]['lr'] = lr_decay * learning_rate\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "\n",
    "            optimizer.step()  # Calling the step function on the Optimizer \n",
    "\n",
    "        X = torch.cat((X_test[i], X_test[j]), 0).float()\n",
    "        Y = torch.cat((y_test[i], torch.zeros(y_test[j].size(), \n",
    "                                              dtype=torch.double)), 0).long()\n",
    "        #X = (X - mean)/std        \n",
    "        \n",
    "        Y_pred = model(X)\n",
    "\n",
    "        error_train_list_all.append(int(sum(abs(torch.argmax(y_pred, axis=1)-y)))/y.shape[0])\n",
    "        error_test_list_all.append(int(sum(abs(torch.argmax(Y_pred, axis=1)-Y)))/Y.shape[0])\n",
    "\n",
    "    mean_train_error += np.mean(error_train_list_all)\n",
    "    mean_test_error += np.mean(error_test_list_all)\n",
    "    var_test_error += np.var(error_test_list_all)\n",
    "\n",
    "mean_train_error /= num_trials\n",
    "mean_test_error /= num_trials\n",
    "var_test_error /= num_trials\n",
    "\n",
    "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=20$, $\\sigma=0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, sigma = 0.3, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.7 , Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer         200       None           0.01   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.0459      0.1679          0.0044  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'sigma = 0.3,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Distance, $|Q|=20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Tanh, Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer          20       None          0.005   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.0683      0.0881          0.0032  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'Old Distance,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Tanh,\", \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "models = [\"Fully Connected 1-Layer\"]\n",
    "\n",
    "for k in range(len(models)): \n",
    "    Dic_1[k+1] = [models[k], H[0], None, learning_rate, \"len(x)\", \n",
    "                  np.round(mean_train_error, decimals = 4), \n",
    "                  np.round(mean_test_error, decimals = 4),\n",
    "                  np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', columns=['Classifier', 'Hidden dim', \n",
    "                                                              'Drop Out p', 'Learning Rate',\n",
    "                                                              'Batch Normalization', 'Train Error', \n",
    "                                                              'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=50$, $\\sigma=0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, sigma = 0.25, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.8 , Number of Updates =  200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.1882</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer         500       None           0.01   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)        0.008      0.1882          0.0052  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'sigma = 0.25,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Distance, $|Q|=50$, $\\sigma=1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, sigma = 1000, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.8 , Number of Updates =  1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer         200       None           0.05   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.0692      0.2616          0.0084  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'sigma = 1000,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Distance, $|Q|=50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.4 , Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hidden dim</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normalization</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Variance Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 1-Layer</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hidden dim Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 1-Layer         500       None           0.01   \n",
       "\n",
       "  Batch Normalization  Train Error  Test Error  Variance Error  \n",
       "1              len(x)       0.0191      0.0531           0.001  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'Old Distance,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", \"Learning Decay =\", lr_decay, \n",
    "      \", Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hidden dim', \n",
    "                                       'Drop Out p', 'Learning Rate',\n",
    "                                       'Batch Normalization', 'Train Error', \n",
    "                                       'Test Error', 'Variance Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_project_classifiers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
