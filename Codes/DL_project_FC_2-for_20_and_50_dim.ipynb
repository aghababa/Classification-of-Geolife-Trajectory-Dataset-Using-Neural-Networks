{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "V-xJxlvIlCjB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "from scipy import linalg as LA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "3Baay7UJlCjG"
   },
   "outputs": [],
   "source": [
    "float = np.vectorize(float)\n",
    "\n",
    "def read_file(file_name):\n",
    "    data = []\n",
    "    with open(file_name, \"r\") as f:\n",
    "        for line in f:\n",
    "            item = line.strip().split(\",\")\n",
    "            data.append(float(item))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "XD6GckUylCjI"
   },
   "outputs": [],
   "source": [
    "#I = glob.glob('DL Project/20-dim data (41) representation sigma=0.3/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/20-dim data (41) representation old distamce/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/50-dim data (41) representation sigma=0.25/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/50-dim data (41) representation sigma=1000/*.csv', recursive=True)\n",
    "I = glob.glob('DL Project/50-dim data (41) representation old distamce/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/250-dim data (41) representation sigma=1/*.csv', recursive=True)\n",
    "#I = glob.glob('DL Project/250-dim data (41) representation old distamce/*.csv', recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = len(I)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embed = [0] * r\n",
    "\n",
    "for i in range(r):\n",
    "    data_embed[i] = [len(np.array(read_file(I[i]))), np.array(read_file(I[i]))]\n",
    "\n",
    "data_embed = np.array(data_embed)\n",
    "#data_embed = data_embed[data_embed[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "abqsEqTalCjK"
   },
   "outputs": [],
   "source": [
    "X_train = [0] * r\n",
    "X_test = [0] * r\n",
    "y_train = [0] * r\n",
    "y_test = [0] * r\n",
    "\n",
    "for i in range(r):\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(np.array(data_embed[i][1]), \n",
    "                                                                np.ones(len(data_embed[i][1])), \n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(r):\n",
    "    X_train[i] = torch.tensor(X_train[i])\n",
    "    X_test[i] = torch.tensor(X_test[i])\n",
    "    y_train[i] = torch.tensor(y_train[i])\n",
    "    y_test[i] = torch.tensor(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0894, 0.0895, 0.1878, 0.2237, 0.2487, 0.2606, 0.2174, 0.1535, 0.1233,\n",
       "        0.0230, 0.0381, 0.1052, 0.1446, 0.1522, 0.0785, 0.0747, 0.2651, 0.3137,\n",
       "        0.3166, 0.4247, 0.4089, 0.3639, 0.4056, 0.3045, 0.4469, 0.2612, 0.3823,\n",
       "        0.3474, 0.5713, 0.6286, 0.7101, 0.6100, 0.6540, 0.6263, 0.6342, 0.3726,\n",
       "        0.2940, 0.6580, 0.6909, 1.0120, 1.3365, 1.4892, 1.7201, 0.5754, 0.5765,\n",
       "        1.1204, 1.1804, 0.3535, 0.4736, 0.6166], dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([407, 544, 112, 371, 154, 394, 147, 423, 2014, 167, 101, 215, 150,\n",
       "       583, 318, 173, 148, 146, 150, 196, 747, 295, 100, 260, 389, 2124,\n",
       "       275, 182, 160, 108, 226, 196, 113, 207, 144, 800, 678, 120, 106,\n",
       "       382, 133], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_embed[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Layer Fully Connected Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3003592491149902\n",
      "100 1.6519252061843872\n",
      "200 1.503686785697937\n",
      "300 1.3084096908569336\n",
      "400 1.1010472774505615\n",
      "500 0.9221939444541931\n",
      "600 0.7896917462348938\n",
      "700 0.6678414344787598\n",
      "800 0.5557985305786133\n",
      "900 0.4554961025714874\n",
      "1000 0.3696424663066864\n",
      "1100 0.30116137862205505\n",
      "1200 0.24994729459285736\n",
      "1300 0.21155938506126404\n",
      "1400 0.18389835953712463\n",
      "1500 0.1638399213552475\n",
      "1600 0.14930959045886993\n",
      "1700 0.13878008723258972\n",
      "1800 0.13090552389621735\n",
      "1900 0.12483219057321548\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU5b3H8c8vM9kXSEhkR8IuyCJGFFHRqyJ6K1S9LrR1uWpRr1q1t622trW11Vq9tdrWarHlutS6VKty3XCpihtKUFbZN4lsgbAEQvbn/jEHOmCWCZnMmUy+79drXnPOc86Z+eVM8p2TszzHnHOIiEjiSvK7ABERaVsKehGRBKegFxFJcAp6EZEEp6AXEUlwQb8LaEh+fr7r27ev32WIiLQbc+fO3eqcK2hoWlwGfd++fSkuLva7DBGRdsPM1jU2TbtuREQSnIJeRCTBKehFRBKcgl5EJMEp6EVEEpyCXkQkwSnoRUQSXMIEvXOO3721gneXl/pdiohIXEmYoDczHp61mreXbvG7FBGRuJIwQQ+Qm5nCjopqv8sQEYkriRX0GcmUVdT4XYaISFxJrKDXFr2IyFckVNDnZaRQtkdBLyISLqGCvnNGCtsV9CIiB0iooM/LTGZPdR1VtXV+lyIiEjcSKuhzM1MA2KEDsiIi+zUb9GY23cy2mNmiRqZ/38zmeY9FZlZnZnnetLVmttCb1uZ3EsnNCAW99tOLiPxLJFv0jwATG5vonLvHOTfKOTcK+CHwrnOuLGyWU7zpRa0rtXn7gn67zrwREdmv2aB3zs0CypqbzzMFeLJVFbVCnrfrZvse7boREdknavvozSyD0Jb/c2HNDnjdzOaa2dRmlp9qZsVmVlxaemj91eRmJANQpi16EZH9onkw9mzgg4N224xzzo0GzgSuNbOTGlvYOTfNOVfknCsqKGjwRubN6uztutmhffQiIvtFM+gv4qDdNs65Dd7zFuB5YEwU3+8rUoJJZKcGtUUvIhImKkFvZp2A8cCLYW2ZZpa9bxiYADR45k40dc5M1kVTIiJhgs3NYGZPAicD+WZWAtwGJAM45x7yZjsHeN05tyds0a7A82a2733+5px7LXqlNywvI4XtOo9eRGS/ZoPeOTclgnkeIXQaZnjbamDkoRZ2qHIz1d+NiEi4hLoyFkLn0us8ehGRf0nMoNd59CIi+yVg0Cezu6qW6tp6v0sREYkLiRf0+zs20+4bERFIwKDf1w2CzqUXEQlJuKDvvK8bBJ15IyICJGDQ56lPehGRAyRe0KtPehGRAyRc0O/r2EzdIIiIhCRc0KcEk8hKDaobBBERT8IFPUBuZrKujhUR8SRm0GeovxsRkX0SNui1RS8iEpKQQZ+flcrW8iq/yxARiQsJGfTdOqWypbyKunrndykiIr5LzKDPSaO23rFtt7bqRUQSMui75qQBsGlXpc+ViIj4LyGDvlsnL+h3KuhFRBIz6LVFLyKyX7NBb2bTzWyLmS1qZPrJZrbTzOZ5j5+GTZtoZsvMbKWZ3RLNwptSkJ1KZkqAVVt2x+otRUTiViRb9I8AE5uZ5z3n3CjvcTuAmQWAB4AzgaHAFDMb2ppiI2VmDOyazfLNCnoRkWaD3jk3Cyg7hNceA6x0zq12zlUDTwGTD+F1DskR3bNZtGEnNXW6paCIdGzR2kc/1szmm9mrZjbMa+sJrA+bp8Rra5CZTTWzYjMrLi0tbXVBJw8+jPLKWmYtb/1riYi0Z9EI+k+Bw51zI4HfAy947dbAvI1eweScm+acK3LOFRUUFLS6qPGDCji8SwY/fmERG3bsbfXriYi0V60OeufcLufcbm/4FSDZzPIJbcH3Dpu1F7Chte8XqbTkAA9+82h2V9ZyyfRP1D+9iHRYrQ56M+tmZuYNj/FecxswBxhoZoVmlgJcBMxo7fu1xNAeOTx8aRFflFVw8fSPFfYi0iFFcnrlk8BHwGAzKzGzK8zsajO72pvlP4BFZjYf+B1wkQupBa4DZgJLgGecc4vb5sdo3HH9uvCnbx3N8k27+drv32dByY5YlyAi4itzLv46/ioqKnLFxcVRfc1563dw7ROfUlpexU/OHsq3ju2D94+IiEi7Z2ZznXNFDU1LyCtjGzKqd2deuv4Ejh/QhZ+8sIj/fmY+e6vr/C5LRKTNdZigB8jNTGH6pcdw02mDeH7el5zzxw9Ys3WP32WJiLSpDhX0AElJxg2nDeR/LzuGTbsqmfT793l98Sa/yxIRaTMdLuj3OXnwYbx0/QkUFmQy9fG53P3aUup1oxIRSUAdNugBeuVm8MxVY5kypjd/fGcVNz+3QHelEpGEE/S7AL+lJQe485zhHJadxv1vrWBvTR33X3QUgSSdkSMiiaHDBz2Eeru86fRBpKcEuOvVpeRlpvDzScN0+qWIJAQFfZirx/enbE8102atpmfndK4a39/vkkREWk1Bf5BbJg7hyx17ueu1pQzr0YkTBub7XZKISKt06IOxDUlKMu4+bwQDCrK44anPdN9ZEWn3FPQNyEwN8uC3RrO3po7rn/yUWt28RETaMQV9IwYcls0d5xzJnLXbefCdVX6XIyJyyBT0TTjnqF5MGtmD+95awbz16vVSRNonBX0zfjH5SLpmp3LT0/OoqK71uxwRkRZT0DejU0Yy/3PBSNZu28MvX17idzkiIi2moI/A8f3zmXpiP/728Re8+flmv8sREWkRBX2EvjthEEd0z+Hm5xawbXeV3+WIiERMQR+h1GCA3144kl2VNfzkxUXE4525REQaoqBvgSHdcrjxtEG8snATLy3Y6Hc5IiIRieTm4NPNbIuZLWpk+jfNbIH3+NDMRoZNW2tmC81snplF9yawPrnqpH6M7N2Zn7y4iC3lumpWROJfJFv0jwATm5i+BhjvnBsB/AKYdtD0U5xzoxq7aW17Ewwk8ZvzR1BRXceP/qFdOCIS/5oNeufcLKCsiekfOue2e6OzgV5Rqi1uDTgsm+9PGMybSzbz/Gdf+l2OiEiTor2P/grg1bBxB7xuZnPNbGpTC5rZVDMrNrPi0tLSKJcVfZefUEjR4bncNmOxOj4TkbgWtaA3s1MIBf3NYc3jnHOjgTOBa83spMaWd85Nc84VOeeKCgoKolVWmwkkGf9z/khq6uq5+bkF2oUjInErKkFvZiOAPwOTnXPb9rU75zZ4z1uA54Ex0Xi/eNE3P5NbJg7h3eWlPD1nvd/liIg0qNVBb2Z9gH8AFzvnloe1Z5pZ9r5hYALQ4Jk77dklY/sytl8X7nh5iXbhiEhciuT0yieBj4DBZlZiZleY2dVmdrU3y0+BLsAfDzqNsivwvpnNBz4BXnbOvdYGP4OvkpKMu84bTk19PT9+QWfhiEj8afZWgs65Kc1MvxK4soH21cDIry6ReA7vksl3Tx/Ena8s5ZWFm/j3Ed39LklEZD9dGRsll48rZHjPTtw2YxE7Kqr9LkdEZD8FfZQEA0ncdd5wtlfUqDtjEYkrCvooGtajE1ed1I9n55bw/oqtfpcjIgIo6KPuO6cOpDA/kx8+v0B3pBKRuKCgj7K05AB3nTuc9WV7uff15c0vICLSxhT0beDYfl34xrF9mP7BGubrpuIi4jMFfRu55cwhFGSncvNzC6ipq/e7HBHpwBT0bSQnLZnbJx/J0k3lTJu12u9yRKQDU9C3oTOGdWPisG7c/9YK1mzd43c5ItJBKejb2M8nDyM1mMQP/6EeLkXEHwr6NtY1J40fnXUEs1eX8UyxergUkdhT0MfAhUW9GVOYxx0vL9F9ZkUk5hT0MZCUZPzq3OFU1tbz8xmf+12OiHQwCvoY6V+QxXf+bQAvL9zIG59v9rscEelAFPQxNPWk/gzpls1PXlhEeWWN3+WISAehoI+hlGASvzp3OJvLK7ln5jK/yxGRDkJBH2NH9cnlsuP78vjsdcxdV+Z3OSLSASjoffC9CYPp0Smdm59bSFVtnd/liEiCU9D7IDM1yC/POZKVW3bz4Dur/C5HRBJcREFvZtPNbIuZLWpkupnZ78xspZktMLPRYdMuNbMV3uPSaBXe3p0y+DAmjezBA2+vZMXmcr/LEZEEFukW/SPAxCamnwkM9B5TgQcBzCwPuA04FhgD3GZmuYdabKL56dlDyUwNcss/FlJfr+4RRKRtRBT0zrlZQFNHDicDj7mQ2UBnM+sOnAG84Zwrc85tB96g6S+MDiU/K5Uf//tQ5q7bzhOffOF3OSKSoKK1j74nEN6RS4nX1lj7V5jZVDMrNrPi0tLSKJUV/84b3ZMTBuTz61eXsnHnXr/LEZEEFK2gtwbaXBPtX210bppzrsg5V1RQUBClsuKfmXHnOcOpra/nJy8sVg+XIhJ10Qr6EqB32HgvYEMT7RKmT5cMvnv6IN5csplXF23yuxwRSTDRCvoZwCXe2TfHATudcxuBmcAEM8v1DsJO8NrkIJePK+TInjncNmMxOyvUPYKIRE+kp1c+CXwEDDazEjO7wsyuNrOrvVleAVYDK4GHgf8CcM6VAb8A5niP2702OUgwkMRd546gbE81v3p1id/liEgCCUYyk3NuSjPTHXBtI9OmA9NbXlrHc2TPTlx5QiF/mrWaSSN7cPyAfL9LEpEEoCtj48yNpw2iMD+T7z+7QD1cikhUKOjjTHpKgP85fyQbd+7ljpe1C0dEWk9BH4eOPjyXq8b356k563l72Ra/yxGRdk5BH6duPG0gg7tmc/OzC9hRUe13OSLSjino41RqMMBvLhhJ2Z5qfjZjsd/liEg7pqCPY0f27MR3Th3IC/M28OrCjX6XIyLtlII+zl1zcn9G9OrErS8sYuvuKr/LEZF2SEEf55IDSfzm/JHsrqrl5mcXqC8cEWkxBX07MLBrNj86cwhvLd3CYx+t87scEWlnFPTtxKXH9+WUwQXc8coSlm7a5Xc5ItKOKOjbCTPjnvNHkpOWzHee/IzKGt1UXEQio6BvR/KzUrn3gpEs37xbV82KSMQU9O3MSYMK+PaJhTw+ex2vL1bf9SLSPAV9O/T9M4ZwZM8cfvDcAt1+UESapaBvh1KCSdx/0VHU1NZz3d8+o6au3u+SRCSOKejbqf4FWfzqvBHMXbedu19b6nc5IhLHFPTt2KSRPbhk7OE8/N4aZmp/vYg0QkHfzt3670cwslcnvvf3+XyxrcLvckQkDino27nUYIA/fGM0SWZc88RcnV8vIl8R6c3BJ5rZMjNbaWa3NDD9t2Y2z3ssN7MdYdPqwqbNiGbxEtI7L4N7LxjJ4g27+Pn/fe53OSISZ5q9ObiZBYAHgNOBEmCOmc1wzu1PFOfcTWHzXw8cFfYSe51zo6JXsjTk1CO6cvX4/jz07ipG9+nM+UW9/S5JROJEJFv0Y4CVzrnVzrlq4ClgchPzTwGejEZx0jLfmzCIcQO6cOsLi5i3fkfzC4hIhxBJ0PcE1oeNl3htX2FmhwOFwD/DmtPMrNjMZpvZ1xt7EzOb6s1XXFpaGkFZcrBgIInfTxnNYdmpXP34XLaUV/pdkojEgUiC3hpoa6xT9IuAZ51z4UcE+zjnioBvAPeZWf+GFnTOTXPOFTnnigoKCiIoSxqSl5nCtIuL2LG3mmuf+JTqWl1MJdLRRRL0JUD4Dt9ewIZG5r2Ig3bbOOc2eM+rgXc4cP+9tIGhPXK4+z9GMmftdm5/SfebFenoIgn6OcBAMys0sxRCYf6Vs2fMbDCQC3wU1pZrZqnecD4wDtBpITEwaWQPrhrfj7/O/oInP/nC73JExEfNBr1zrha4DpgJLAGecc4tNrPbzWxS2KxTgKfcgfe6OwIoNrP5wNvAXeFn60jb+sEZQzhxYD4/fXERc9eV+V2OiPjE4vEepEVFRa64uNjvMhLCjopqvv7AB5RX1vLCtePonZfhd0ki0gbMbK53PPQrdGVsguuckcJfLjuGmrp6Ln9kDrsqa/wuSURiTEHfAfQvyOKhi49mzdY9XPvEp+rWWKSDUdB3EMf3z+fOc4bz3oqt/GzGYuJxl52ItI1mu0CQxHHBMb1ZvXUPD727in4FWVxxQqHfJYlIDCjoO5gfnDGYtVv38MuXP6d3bjoThnXzuyQRaWPaddPBJCUZv71wFCN6dea6Jz/j/RVb/S5JRNqYgr4DSk8J8Oh/HkO//Ey+/Vgxby/d4ndJItKGFPQdVOeMFB6/4lj6H5bJlY8V87ePdfWsSKJS0HdgBdmpPD11LCcNzOdHzy/knplLdTaOSAJS0HdwmalBHr6kiCljevPA26u46el56vFSJMHorBshGEjiznOG0ys3g3tmLmPzrioeuvhoOqUn+12aiESBtugFADPj2lMGcO8FI5mztozzH/qQku0VfpclIlGgoJcDnDu6F49ePoaNOyv5+gMfqNdLkQSgoJevGDcgn+f/axxZqUGmTPuYZ+eW+F2SiLSCgl4aNOCwLF64dhxFfXP53t/n86tXllBXrzNyRNojBb00qnNGCo9ePoZvHdeHP81azdTHiilXN8ci7Y6CXpqUHEjil18fzi8mD+Od5aWc9+CHfLFNB2lF2hMFvUTk4rF9eezyMWzeVcXZf3ift5ep2wSR9kJBLxEbNyCfGdeNo0fndC5/ZA73v7mCeu23F4l7EQW9mU00s2VmttLMbmlg+mVmVmpm87zHlWHTLjWzFd7j0mgWL7F3eJdM/nHN8Zwzqie/fXM5Vz5WzM4K7bcXiWfNBr2ZBYAHgDOBocAUMxvawKxPO+dGeY8/e8vmAbcBxwJjgNvMLDdq1Ysv0lMC/OaCkfxi8jDeW1HK2X94n8837PK7LBFpRCRb9GOAlc651c65auApYHKEr38G8IZzrsw5tx14A5h4aKVKPDEzLh7bl6emjqWqto5zH/xA59uLxKlIgr4nsD5svMRrO9h5ZrbAzJ41s94tXBYzm2pmxWZWXFpaGkFZEg+OPjyXl64/kVG9O/O9v8/npqfnsbuq1u+yRCRMJEFvDbQdfATu/4C+zrkRwJvAoy1YNtTo3DTnXJFzrqigoCCCsiReFGSn8sSVx3HTaYN4cd6XfO1377Hoy51+lyUinkiCvgToHTbeC9gQPoNzbptzrsobfRg4OtJlJTEEkowbThvIk98+jsqaes7944dMf3+N+rcXiQORBP0cYKCZFZpZCnARMCN8BjPrHjY6CVjiDc8EJphZrncQdoLXJgnq2H5dePWGEzlpUD63v/Q5336smG27q5pfUETaTLNB75yrBa4jFNBLgGecc4vN7HYzm+TN9h0zW2xm84HvAJd5y5YBvyD0ZTEHuN1rkwSWm5nCw5cUcdvZQ5m1fCtn3Pceb36+2e+yRDosi8d/rYuKilxxcbHfZUgULNm4i5uensfSTeVcWNSbH3/tCLLTdEMTkWgzs7nOuaKGpunKWGlTR3TP4cXrxvFfJ/fn73PXc+b97/Hx6m1+lyXSoSjopc2lBgP8YOIQnrlqLElmXPTwbO54+XMqa+r8Lk2kQ1DQS8wU9c3j1RtOZMqYPjz83hom3jeLj1Zp616krSnoJaYyU4Pcec5wnrjyWOodTHl4Nrc8t4Cde9VfjkhbUdCLL8YNyGfmjSdx1Un9eKZ4Paff+y6vLdrkd1kiCUlBL75JTwnww7OO4MVrTyA/K5Wr/zqXqx4v5ssde/0uTSShKOjFd8N7deLF68Zx88QhvLu8lNN+8y4PvL2SqlodrBWJBgW9xIXkQBLXnNyfN787nvGDCrhn5jIm3vce7+hOViKtpqCXuNIrN4OHLj6aRy8fA8Bl/zuHqY8Vs75M96kVOVQKeolL4wcV8NqNJ/L9Mwbz3oqtnHrvu9z16lJ2VersHJGWUtBL3EoNBrj2lAG89d/j+drw7jz07ipOvucdHv1wLTV19X6XJ9JuKOgl7vXonM69F47ipetPYHDXbG6bsZgJv53FzMWb1A2ySAQU9NJuHNmzE3/79rFMv6yIQJJx1eNzOe/BD/lg5VYFvkgTFPTSrpgZ/zakK6/dcCJ3njOcjTsr+eafP+bCabPVWZpII9RNsbRrlTV1PD1nPQ+8vZIt5VWcMCCfm04fxNGH5/pdmkhMNdVNsYJeEkJlTR1/nb2Oh95dxdbd1Ywb0IVrxg9g3IAumDV062KRxKKglw6jorqWxz9ax1/eX8OW8iqG9+zENSf354xh3QgkKfAlcSnopcOpqq3j+U+/5E+zVrNm6x4K8zP59on9OHd0T9KSA36XJxJ1CnrpsOrqHTMXb+LBd1ax8MuddM5I5sJjenPxcYfTKzfD7/JEoqbVQW9mE4H7gQDwZ+fcXQdN/y5wJVALlAKXO+fWedPqgIXerF845ybRDAW9RJtzjo/XlPHoh2uZuTjUHfJpR3TlsuP7Mra/9uNL+9eqoDezALAcOB0oAeYAU5xzn4fNcwrwsXOuwsyuAU52zl3oTdvtnMtqScEKemlLX+7Yy19nr+OpT75ge0UNAw/L4sJjenPu6F7kZab4XZ7IIWlt0I8FfuacO8Mb/yGAc+5Xjcx/FPAH59w4b1xBL3GpsqaOGfM38MTsdcwv2UlywDh9aFfOL+rNSQMLdPBW2pWmgj4YwfI9gfVh4yXAsU3MfwXwath4mpkVE9qtc5dz7oVGipwKTAXo06dPBGWJtE5acoALinpzQVFvlm7axTNzSnj+sxJeWbiJbjlpnHd0T74+qicDu2b7XapIq0SyRX8+cIZz7kpv/GJgjHPu+gbm/RZwHTDeOVfltfVwzm0ws37AP4FTnXOrmnpPbdGLX6pr63lzyWaeKV7PrOWl1DsY0i2bSaN6cPaIHvTO0wFciU+t3aIvAXqHjfcCNjTwJqcBtxIW8gDOuQ3e82ozewc4Cmgy6EX8khJM4qzh3TlreHe2lFfy8oKNzJi/gbtfW8bdry3jqD6dmTSyBxOGdaNn53S/yxWJSCRb9EFCB2NPBb4kdDD2G865xWHzHAU8C0x0zq0Ia88FKpxzVWaWD3wETA4/kNsQbdFLvFlfVsH/LdjAjHkbWLqpHIBhPXI4fWhXTh/alaHdc3TmjvgqGqdXngXcR+j0yunOuTvM7Hag2Dk3w8zeBIYDG71FvnDOTTKz44E/AfWEOlC7zzn3l+beT0Ev8WxV6W7e+Hwzb3y+mU+/2I5z0LNzOqcP7crJgws4trAL6Sm6KEtiSxdMibSR0vIq/rl0M68v3sz7K7dSVVtPSjCJMX3zOHFgPicOLOCI7tna2pc2p6AXiYG91XV8sraM95aX8t6KrSzbHNrFk5+VygkDujCmsAtjCnPpX5Cl4Jeoa+3BWBGJQHpKgPGDChg/qACATTsreW9FKPTfX7mNF+aFzmHIy0yh6PBcxhTmMaYwj6HdcwgGdGsIaTvaoheJAecca7dV8MmabXyyZjtz1pbxRVkFAGnJSRzZoxMjenVmZO/Qc98uGdrqlxbRrhuROLRpZyWfrC3jsy+2s6BkJ4s37KSyJnTT85y0ICN6dWZEr04M6Z7DEd2yKczP1Ja/NEpBL9IO1NbVs3zzbhaU7GB+yU4WlOxg2aZyautDf6MpwSQGFGQxpHs2Q7plM6RbDoO6ZtM1J1Vb/6KgF2mvqmrrWLVlD8s272LpxnKWbCpn2aZdbN61/5pEMlICFOZn0q8gi8L8TPoXZFKYH3pkpyX7WL3Ekg7GirRTqcEAQ3vkMLRHTuiacs/2PdUs3VTOii3lrC7dw5qte5i/fgcvL9hAfdi2W35WKn3y0umZm0Gv3HTvERru2TldN2HpIBT0Iu1QbmYKY/t3YWz/Lge0V9XW8cW2ClZv3eN9Aezmyx17WVCyg9cWbaSm7sD/4POzUumVm063nDS65qRyWE4aXb3hrjlpdM1OIyc9qF1D7ZyCXiSBpAYDDOya3WCPm3X1ji3llZRs30vJ9gpKyvaGhndUsLJ0Nx+s2kp5ZW0Dr5lE15w0DstOpUtWCnmZqXTJTCEvM8Ub94YzU8nNTCY1qP8S4o2CXqSDCCQZ3Tul071TOsf0zWtwnorqWrbsqmLzrko2l1exZVclW8q98V2VrC7dQ/Ha7WyvqD5gF1G4rNQgeZkp5GamkJMWJCc9mU7pyeSkJZOTHgwb3tcemicnLZmUoM4qagsKehHZLyMlSN/8IH3zM5ucr67esXNvDWV7qr1HFdv2VFO2u5qyiur97eWVtXy5Yy+79tawc2/NV3YdHSw1mERWapCM1ACZKUEyU4NkpARCbSlBslIDZKQGvfEAmalBMlNC82elBklPDpCWnERqMEB6SoC05ABpwaQOf1qqgl5EWiyQZPt32UTKOUdVbT0799awa28Nuypr2LW3NjReGWorr6xlT3Ute6rq2FMVGi6vrGXTzkoqquvYXVXLnqra/aecRiqYZKHQ974I9j2ne22pwX+1pycHSAkmkRJMIjmQRGowiZRAEskBIyUY8J5DbeHzhbcdML6/zXz7wlHQi0hMmP0rbLvmpLXqtapq66ioCgV/+BdAZU0dlbX1VFbXUVlbFxqvqaeypo693nBVTWja3urQ+O6qWrburqZq/zx1VNfWU11X3+x/IC1lBslJSQQDRrL35REMGy/ISuWZq8dG9T1BQS8i7VBqMLQVntvGN3N3zu0P/Oraeqpr66mpq6fKe64Oe66qq6dm/xdEvfdl4Q6Yp8Z7rZq6emrr6qmpd9TW1VNb56ipd2Slts2BbAW9iEgjzMz7UgFS/a7m0HXsIxQiIh2Agl5EJMEp6EVEEpyCXkQkwUUU9GY20cyWmdlKM7ulgempZva0N/1jM+sbNu2HXvsyMzsjeqWLiEgkmg16MwsADwBnAkOBKWY29KDZrgC2O+cGAL8Ffu0tOxS4CBgGTAT+6L2eiIjESCRb9GOAlc651c65auApYPJB80wGHvWGnwVOtVB3d5OBp5xzVc65NcBK7/VERCRGIgn6nsD6sPESr63BeZxztcBOoEuEywJgZlPNrNjMiktLSyOrXkREmhXJBVMNdUR98HXBjc0TybKhRuemAdMAzKzUzNZFUFtD8oGth7hsW1JdLaO6WkZ1tUwi1nV4YxMiCfoSoHfYeC9gQyPzlJhZEOgElEW47Fc45woiqKtBZlbc2O20/KS6WkZ1tYzqapmOVlcku27mAAPNrNDMUggdXJ1x0DwzgEu94f8A/ulCNyWzd6wAAAVDSURBVKOdAVzknZVTCAwEPolO6SIiEolmt+idc7Vmdh0wEwgA051zi83sdqDYOTcD+AvwuJmtJLQlf5G37GIzewb4HKgFrnXO1bXRzyIiIg2IqFMz59wrwCsHtf00bLgSOL+RZe8A7mhFjS01LYbv1RKqq2VUV8uorpbpUHVZaA+LiIgkKnWBICKS4BT0IiIJLmGCvrn+eNr4vXub2dtmtsTMFpvZDV77z8zsSzOb5z3OClsmJn0AmdlaM1vovX+x15ZnZm+Y2QrvOddrNzP7nVfXAjMb3UY1DQ5bJ/PMbJeZ3ejX+jKz6Wa2xcwWhbW1eB2Z2aXe/CvM7NKG3isKdd1jZku9937ezDp77X3NbG/YunsobJmjvd+BlV7tDV3f0tq6WvzZRftvtpG6ng6raa2ZzfPaY7K+msiG2P5+Oefa/YPQ2UCrgH5ACjAfGBrD9+8OjPaGs4HlhPoF+hnwvQbmH+rVmAoUerUH2qi2tUD+QW13A7d4w7cAv/aGzwJeJXSh23HAxzH67DYRutjDl/UFnASMBhYd6joC8oDV3nOuN5zbBnVNAILe8K/D6uobPt9Br/MJMNar+VXgzDaoq0WfXVv8zTZU10HTfwP8NJbrq4lsiOnvV6Js0UfSH0+bcc5tdM596g2XA0topKsHj999AIX3TfQo8PWw9sdcyGygs5l1b+NaTgVWOeeauhK6TdeXc24WodOCD37PlqyjM4A3nHNlzrntwBuEOvKLal3OudddqJsRgNmELkJslFdbjnPuIxdKjMfCfpao1dWExj67qP/NNlWXt1V+AfBkU68R7fXVRDbE9PcrUYI+4j512pqFumg+CvjYa7rO+xds+r5/z4htvQ543czmmtlUr62rc24jhH4RgcN8qGufizjwj8/v9bVPS9eRHzVeTmjrb59CM/vMzN41sxO9tp5eLbGoqyWfXazX14nAZufcirC2mK6vg7Ihpr9fiRL0Efep06ZFmGUBzwE3Oud2AQ8C/YFRwEZC/zpCbOsd55wbTaib6WvN7KQm5o3perTQldaTgL97TfGwvprT6n6dolKE2a2ELkJ8wmvaCPRxzh0FfBf4m5nlxLCuln52sf5Mp3DgBkVM11cD2dDorI28f6vqSpSgP6Q+daLJzJIJfZBPOOf+AeCc2+ycq3PO1QMP86/dDTGr1zm3wXveAjzv1bB53y4Z73lLrOvynAl86pzb7NXo+/oK09J1FLMavQNxXwO+6e1ewNs1ss0bnkto//cgr67w3TttUtchfHaxXF9B4Fzg6bB6Y7a+GsoGYvz7lShBH0l/PG3G2//3F2CJc+7esPbw/dvnAPvOBohJH0Bmlmlm2fuGCR3IW8SBfRNdCrwYVtcl3pH/44Cd+/69bCMHbGX5vb4O0tJ1NBOYYGa53m6LCV5bVJnZROBmYJJzriKsvcC8m/qYWT9C62i1V1u5mR3n/Z5eEvazRLOuln52sfybPQ1Y6pzbv0smVuursWwg1r9fh3o0Od4ehI5WLyf0zXxrjN/7BEL/Ri0A5nmPs4DHgYVe+wyge9gyt3q1LqOVZ0E0UVc/QmczzAcW71svhO4V8BawwnvO89qN0N3EVnl1F7XhOssAtgGdwtp8WV+Evmw2AjWEtpyuOJR1RGif+Urv8Z9tVNdKQvtq9/2ePeTNe573Gc8HPgXODnudIkLBuwr4A94V8VGuq8WfXbT/Zhuqy2t/BLj6oHljsr5oPBti+vulLhBERBJcouy6ERGRRijoRUQSnIJeRCTBKehFRBKcgl5EJMEp6EVEEpyCXkQkwf0/Ico4OHSL05oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Start_time = time.time()\n",
    "\n",
    "mean_train_error = 0\n",
    "mean_test_error = 0\n",
    "var_test_error = 0\n",
    "\n",
    "\n",
    "lr_decay = 0.8\n",
    "num_trials = 1\n",
    "learning_rate = 1e-3\n",
    "Num_updates = 2000\n",
    "losses = torch.zeros(num_trials, r-1, Num_updates)\n",
    "\n",
    "for s in range(num_trials):\n",
    "\n",
    "    error_train_list_all = []\n",
    "    error_test_list_all = []\n",
    "\n",
    "    Start_time_2 = time.time()\n",
    "\n",
    "    for i in range(r-9): \n",
    "\n",
    "        x = torch.cat((X_train[i], X_train[i+1], X_train[i+2], X_train[i+3], \n",
    "                       X_train[i+4],X_train[i+5], X_train[i+6], X_train[i+7],\n",
    "                       X_train[i+8], X_train[i+9]), 0).float()\n",
    "        y = torch.cat((0 * y_train[i], y_train[i+1], 2 * y_train[i+2], 3 * y_train[i+3],\n",
    "                       4 * y_train[i+4], 5 * y_train[i+5], 6 * y_train[i+6], 7* y_train[i+7],\n",
    "                       8 * y_train[i+8], 9 * y_train[i+9]), 0).long()\n",
    "\n",
    "        N = len(x) # N is batch size\n",
    "        D_in = len(x[0]) # D_in is input dimension\n",
    "        H1 = 200 # H1 is first hidden dimension, \n",
    "        H2 = 50 # H2 is second hidden dimension, \n",
    "        D_out = 10 # D_out is output dimension\n",
    "\n",
    "        model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(D_in, H1),\n",
    "                                    #torch.nn.LeakyReLU(0.01),\n",
    "                                    torch.nn.Tanh(),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H1, H2),\n",
    "                                    #torch.nn.LeakyReLU(0.01),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    torch.nn.Tanh(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H2, D_out)\n",
    "                                    )\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for t in range(Num_updates):\n",
    "            y_pred = model(x) # of shape (N,D_out)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            losses[s, i, t] = loss\n",
    "\n",
    "            if i == 20:\n",
    "                if t % 100 == 0:\n",
    "                    print(t, loss.item())\n",
    "            \n",
    "            if (t+1) % 500 == 0:\n",
    "                optimizer.param_groups[0]['lr'] = lr_decay * learning_rate\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "\n",
    "            optimizer.step()  # Calling the step function on the Optimizer \n",
    "\n",
    "        X = torch.cat((X_test[i], X_test[i+1], X_test[i+2], X_test[i+3], \n",
    "                       X_test[i+4],X_test[i+5], X_test[i+6], X_test[i+7],\n",
    "                       X_test[i+8], X_test[i+9]), 0).float()\n",
    "        Y = torch.cat((0 * y_test[i], y_test[i+1], 2 * y_test[i+2], 3 * y_test[i+3],\n",
    "                       4 * y_test[i+4], 5 * y_test[i+5], 6 * y_test[i+6], 7* y_test[i+7],\n",
    "                       8 * y_test[i+8], 9 * y_test[i+9]), 0).long()\n",
    "        \n",
    "        Y_pred = model(X)\n",
    "        \n",
    "        error_train_list_all.append((torch.argmax(y_pred, 1) != y).sum().float()/len(y))\n",
    "        error_test_list_all.append((torch.argmax(Y_pred, 1) != Y).sum().float()/len(Y))\n",
    "\n",
    "    mean_train_error += np.mean(error_train_list_all)\n",
    "    mean_test_error += np.mean(error_test_list_all)\n",
    "    var_test_error += np.var(error_test_list_all)\n",
    "\n",
    "mean_train_error /= num_trials\n",
    "mean_test_error /= num_trials\n",
    "var_test_error /= num_trials\n",
    "\n",
    "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Distance, $|Q|=50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.4827</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2  Learning Rate  Train Error  \\\n",
       "1  Fully Connected 2-Layer        200         50          0.001       0.0356   \n",
       "\n",
       "   Test Error  Var_Error  \n",
       "1      0.4827     0.0083  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, learning_rate, \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2',  \n",
    "                                       'Learning Rate', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=50$, $\\sigma=1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, New Distance, sigma=1000, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.8, Number of Updates =  1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2  Learning Rate  Train Error  \\\n",
       "1  Fully Connected 2-Layer        300         50           0.02        0.474   \n",
       "\n",
       "   Test Error  Var_Error  \n",
       "1      0.5478     0.0059  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'New Distance,', 'sigma=1000,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", 'Learning Decay = 0.8,', \n",
    "      \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, learning_rate, \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2',  \n",
    "                                       'Learning Rate', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=50$, $\\sigma=0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, New Distance, sigma=0.25, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.8, Number of Updates =  100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2  Learning Rate  Train Error  \\\n",
       "1  Fully Connected 2-Layer        500        200           0.01       0.0375   \n",
       "\n",
       "   Test Error  Var_Error  \n",
       "1      0.4334     0.0074  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'New Distance,', 'sigma=0.25,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, learning_rate, \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2',  \n",
    "                                       'Learning Rate', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=20$, $\\sigma=0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, New Distance, sigma=0.3, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.01), Learning Decay = 0.8, Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2  Learning Rate  Train Error  \\\n",
       "1  Fully Connected 2-Layer         50         20           0.01        0.307   \n",
       "\n",
       "   Test Error  Var_Error  \n",
       "1      0.4337     0.0046  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'New Distance,', 'sigma=0.3,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.01),\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, learning_rate, \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2',  \n",
    "                                       'Learning Rate', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Distance, $|Q|=20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer         50         20       None          0.001   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.1693       0.212     0.0015  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "models = [\"Fully Connected 2-Layer\"]\n",
    "\n",
    "for k in range(len(models)): \n",
    "    Dic_1[k+1] = [models[k], H1, H2, None, learning_rate, \"len(x)\", \n",
    "                  np.round(mean_train_error, decimals = 4), \n",
    "                  np.round(mean_test_error, decimals = 4),\n",
    "                  np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', columns=['Classifier', 'Hid_dim 1',\n",
    "                'Hid_dim 2', 'Drop Out p', 'Learning Rate', 'Batch Normaln', \n",
    "                 'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7542658448219299\n",
      "500 0.5004701614379883\n",
      "1000 0.35352766513824463\n",
      "1500 0.1922881007194519\n",
      "2000 0.12765829265117645\n",
      "2500 0.09131522476673126\n",
      "3000 0.0691358670592308\n",
      "3500 0.054525572806596756\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Start_time = time.time()\n",
    "\n",
    "mean_train_error = 0\n",
    "mean_test_error = 0\n",
    "var_test_error = 0\n",
    "\n",
    "num_trials = 1\n",
    "learning_rate = 1e-3\n",
    "Num_updates = 4000\n",
    "losses = torch.zeros(num_trials, r-1, Num_updates)\n",
    "\n",
    "for s in range(num_trials):\n",
    "\n",
    "    error_train_list_all = []\n",
    "    error_test_list_all = []\n",
    "\n",
    "    Start_time_2 = time.time()\n",
    "\n",
    "    for i in range(r-1): \n",
    "        j = i+1\n",
    "\n",
    "        x = torch.cat((X_train[i], X_train[j]), 0).float()\n",
    "        y = torch.cat((y_train[i], \n",
    "                       torch.zeros(y_train[j].size(), dtype=torch.double)), 0).long()\n",
    "\n",
    "        N = len(x) # N is batch size\n",
    "        D_in = len(x[0]) # D_in is input dimension\n",
    "        H1 = 10 # H1 is first hidden dimension, \n",
    "        H2 = 5 # H2 is second hidden dimension, \n",
    "        D_out = 2 # D_out is output dimension\n",
    "        q = 0.25\n",
    "\n",
    "        model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(D_in, H1),\n",
    "                                    #torch.nn.LeakyReLU(0.1),\n",
    "                                    torch.nn.Tanh(),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H1, H2),\n",
    "                                    #torch.nn.LeakyReLU(0.1),\n",
    "                                    #torch.nn.ReLU(),\n",
    "                                    torch.nn.Tanh(),\n",
    "                                    #torch.nn.Dropout(p=q),\n",
    "                                    torch.nn.Linear(H2, D_out)\n",
    "                                    )\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for t in range(Num_updates):\n",
    "            y_pred = model(x) # of shape (N,D_out)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            losses[s, i, t] = loss\n",
    "\n",
    "            if i == 20:\n",
    "                if t % 500 == 0:\n",
    "                    print(t, loss.item())\n",
    "            \n",
    "            if (t+1) % 100 == 0:\n",
    "                optimizer.param_groups[0]['lr'] = 0.5 * learning_rate\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "\n",
    "            optimizer.step()  # Calling the step function on the Optimizer \n",
    "\n",
    "        X = torch.cat((X_test[i], X_test[j]), 0).float()\n",
    "        Y = torch.cat((y_test[i], torch.zeros(y_test[j].size(), \n",
    "                                              dtype=torch.double)), 0).long()\n",
    "        \n",
    "        Y_pred = model(X)\n",
    "        \n",
    "        error_train_list_all.append((torch.argmax(y_pred, 1) != y).sum().float()/len(y))\n",
    "        error_test_list_all.append((torch.argmax(Y_pred, 1) != Y).sum().float()/len(Y))\n",
    "\n",
    "    mean_train_error += np.mean(error_train_list_all)\n",
    "    mean_test_error += np.mean(error_test_list_all)\n",
    "    var_test_error += np.var(error_test_list_all)\n",
    "\n",
    "mean_train_error /= num_trials\n",
    "mean_test_error /= num_trials\n",
    "var_test_error /= num_trials\n",
    "\n",
    "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Distance, $|Q|=50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=50, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer         10          5       None          0.001   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.0347       0.062     0.0015  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2', 'Drop Out p', \n",
    "                                       'Learning Rate', 'Batch Normaln', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=50$, $\\sigma=1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, New Distance, sigma=1000, Number of Users:  41, Number of Trials =  1\n",
      "Activation = LeakyReLU(0.1), Learning Decay = 0.8, Number of Updates =  1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer         10          5       None           0.01   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.1523      0.2846     0.0102  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'New Distance,', 'sigma=1000,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = LeakyReLU(0.1),\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2', 'Drop Out p', \n",
    "                                       'Learning Rate', 'Batch Normaln', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=50$, $\\sigma=0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, New Distance, sigma=0.25, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer        100         10       None           0.01   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.0087      0.2008     0.0059  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=50,', 'New Distance,', 'sigma=0.25,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2', 'Drop Out p', \n",
    "                                       'Learning Rate', 'Batch Normaln', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Distance, $|Q|=20$, $\\sigma=0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, New Distance, sigma=0.3, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer         10         20       None           0.05   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.0675      0.1844     0.0061  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'New Distance,', 'sigma=0.3,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "\n",
    "Dic_1[1] = [\"Fully Connected 2-Layer\", H1, H2, None, learning_rate, \"len(x)\", \n",
    "              np.round(mean_train_error, decimals = 4), \n",
    "              np.round(mean_test_error, decimals = 4),\n",
    "              np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', \n",
    "                              columns=['Classifier', 'Hid_dim 1', 'Hid_dim 2', 'Drop Out p', \n",
    "                                       'Learning Rate', 'Batch Normaln', \n",
    "                                       'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Distance, $|Q|=20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Q|=20, Old Distance, Number of Users:  41, Number of Trials =  1\n",
      "Activation = Tanh, Learning Decay = 0.8, Number of Updates =  20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Hid_dim 1</th>\n",
       "      <th>Hid_dim 2</th>\n",
       "      <th>Drop Out p</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Normaln</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Var_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fully Connected 2-Layer</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>len(x)</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  Hid_dim 1  Hid_dim 2 Drop Out p  Learning Rate  \\\n",
       "1  Fully Connected 2-Layer         10          5       None          0.001   \n",
       "\n",
       "  Batch Normaln  Train Error  Test Error  Var_Error  \n",
       "1        len(x)       0.0427      0.0776     0.0022  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('|Q|=20,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
    "      'Number of Trials = ', num_trials)\n",
    "print(\"Activation = Tanh,\", 'Learning Decay = 0.8,', \"Number of Updates = \", Num_updates)\n",
    "Dic_1 = {}\n",
    "\n",
    "models = [\"Fully Connected 2-Layer\"]\n",
    "\n",
    "for k in range(len(models)): \n",
    "    Dic_1[k+1] = [models[k], H1, H2, None, learning_rate, \"len(x)\", \n",
    "                  np.round(mean_train_error, decimals = 4), \n",
    "                  np.round(mean_test_error, decimals = 4),\n",
    "                  np.round(var_test_error, decimals = 4)]\n",
    "    \n",
    "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', columns=['Classifier', 'Hid_dim 1',\n",
    "                'Hid_dim 2', 'Drop Out p', 'Learning Rate', 'Batch Normaln', \n",
    "                 'Train Error', 'Test Error', 'Var_Error'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_project_classifiers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
