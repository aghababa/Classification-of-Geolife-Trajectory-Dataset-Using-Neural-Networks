{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project_FC_1_for_250-dim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-xJxlvIlCjB",
        "scrolled": true
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import glob\n",
        "from scipy import linalg as LA\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Le5QRr73E2",
        "outputId": "6d7d9958-9408-4ec5-a5e3-de33c7e0a142"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Baay7UJlCjG"
      },
      "source": [
        "float = np.vectorize(float)\n",
        "\n",
        "def read_file(file_name):\n",
        "    data = []\n",
        "    with open(file_name, \"r\") as f:\n",
        "        for line in f:\n",
        "            item = line.strip().split(\",\")\n",
        "            data.append(float(item))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD6GckUylCjI"
      },
      "source": [
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/20-dim data (41) representation sigma=0.3/*.csv', recursive=True)\n",
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/20-dim data (41) representation old distamce/*.csv', recursive=True)\n",
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/50-dim data (41) representation sigma=0.25/*.csv', recursive=True)\n",
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/50-dim data (41) representation sigma=1000/*.csv', recursive=True)\n",
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/50-dim data (41) representation old distamce/*.csv', recursive=True)\n",
        "#I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/250-dim data (41) representation sigma=1/*.csv', recursive=True)\n",
        "I = glob.glob('/content/gdrive/My Drive/Deep Learning Project/250-dim data (41) representation old distamce/*.csv', recursive=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAaEbqnS7oiH",
        "outputId": "7ce2e08d-0576-4091-d64c-c0d5f43ba630"
      },
      "source": [
        "r = len(I)\n",
        "r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_yTOhcHSOdX"
      },
      "source": [
        "data_embed = [0] * r\n",
        "\n",
        "for i in range(r):\n",
        "    data_embed[i] = [len(np.array(read_file(I[i]))), np.array(read_file(I[i]))]\n",
        "\n",
        "data_embed = np.array(data_embed)\n",
        "#data_embed = data_embed[data_embed[:,0].argsort()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abqsEqTalCjK"
      },
      "source": [
        "X_train = [0] * r\n",
        "X_test = [0] * r\n",
        "y_train = [0] * r\n",
        "y_test = [0] * r\n",
        "\n",
        "for i in range(r):\n",
        "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(np.array(data_embed[i][1]), \n",
        "                                                                np.ones(len(data_embed[i][1])), \n",
        "                                                                test_size=0.3, \n",
        "                                                                random_state=109)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGb2oEWw7oiI"
      },
      "source": [
        "for i in range(r):\n",
        "    X_train[i] = torch.tensor(X_train[i])\n",
        "    X_test[i] = torch.tensor(X_test[i])\n",
        "    y_train[i] = torch.tensor(y_train[i])\n",
        "    y_test[i] = torch.tensor(y_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCueD0Qo7oiI",
        "outputId": "7f3273b3-d3d3-4911-db57-dc6be95a1300"
      },
      "source": [
        "X_train[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.0227e+00, 6.4639e+00, 5.9184e+00, 5.3902e+00, 4.8850e+00, 4.4105e+00,\n",
              "        3.9778e+00, 3.6020e+00, 3.3025e+00, 3.1017e+00, 3.0192e+00, 3.0646e+00,\n",
              "        3.2326e+00, 3.5055e+00, 3.8611e+00, 4.2790e+00, 4.7426e+00, 6.7865e+00,\n",
              "        6.2065e+00, 5.6361e+00, 5.0787e+00, 4.5388e+00, 4.0237e+00, 3.5441e+00,\n",
              "        3.1165e+00, 2.7650e+00, 2.5217e+00, 2.4196e+00, 2.4760e+00, 2.6811e+00,\n",
              "        3.0045e+00, 3.4127e+00, 3.8791e+00, 4.3848e+00, 6.5965e+00, 5.9982e+00,\n",
              "        5.4059e+00, 4.8219e+00, 4.2496e+00, 3.6944e+00, 3.1653e+00, 2.6779e+00,\n",
              "        2.2592e+00, 1.9539e+00, 1.8201e+00, 1.8945e+00, 2.1556e+00, 2.5467e+00,\n",
              "        3.0173e+00, 3.5358e+00, 4.0842e+00, 6.4570e+00, 5.8444e+00, 5.2347e+00,\n",
              "        4.6292e+00, 4.0296e+00, 3.4390e+00, 2.8631e+00, 2.3128e+00, 1.8117e+00,\n",
              "        1.4129e+00, 1.2213e+00, 1.3296e+00, 1.6809e+00, 2.1592e+00, 2.6979e+00,\n",
              "        3.2674e+00, 3.8542e+00, 6.3705e+00, 5.7489e+00, 5.1281e+00, 4.5085e+00,\n",
              "        3.8904e+00, 3.2749e+00, 2.6637e+00, 2.0609e+00, 1.4766e+00, 9.4595e-01,\n",
              "        6.2456e-01, 8.1631e-01, 1.3120e+00, 1.8859e+00, 2.4844e+00, 3.0933e+00,\n",
              "        3.7077e+00, 6.3394e+00, 5.7144e+00, 5.0894e+00, 4.4644e+00, 3.8394e+00,\n",
              "        3.2144e+00, 2.5895e+00, 1.9645e+00, 1.3396e+00, 7.1492e-01, 9.2808e-02,\n",
              "        5.3039e-01, 1.1551e+00, 1.7800e+00, 2.4050e+00, 3.0300e+00, 3.6549e+00,\n",
              "        6.3649e+00, 5.7427e+00, 5.1212e+00, 4.5006e+00, 3.8814e+00, 3.2645e+00,\n",
              "        2.6514e+00, 2.0454e+00, 1.4557e+00, 9.1401e-01, 5.7721e-01, 7.8127e-01,\n",
              "        1.2906e+00, 1.8708e+00, 2.4729e+00, 3.0842e+00, 3.7000e+00, 6.4464e+00,\n",
              "        5.8329e+00, 5.2221e+00, 4.6151e+00, 4.0137e+00, 3.4207e+00, 2.8415e+00,\n",
              "        2.2865e+00, 1.7785e+00, 1.3710e+00, 1.1737e+00, 1.2863e+00, 1.6471e+00,\n",
              "        2.1333e+00, 2.6770e+00, 3.2501e+00, 3.8394e+00, 6.5818e+00, 5.9822e+00,\n",
              "        5.3884e+00, 4.8025e+00, 4.2278e+00, 3.6695e+00, 3.1366e+00, 2.6443e+00,\n",
              "        2.2198e+00, 1.9089e+00, 1.7725e+00, 1.8490e+00, 2.1159e+00, 2.5133e+00,\n",
              "        2.9895e+00, 3.5120e+00, 4.0636e+00, 6.7679e+00, 6.1864e+00, 5.6142e+00,\n",
              "        5.0545e+00, 4.5120e+00, 3.9937e+00, 3.5104e+00, 3.0784e+00, 2.7225e+00,\n",
              "        2.4755e+00, 2.3719e+00, 2.4296e+00, 2.6384e+00, 2.9666e+00, 3.3796e+00,\n",
              "        3.8501e+00, 4.3593e+00, 7.0007e+00, 6.4402e+00, 5.8927e+00, 5.3621e+00,\n",
              "        4.8541e+00, 4.3765e+00, 3.9404e+00, 3.5610e+00, 3.2582e+00, 3.0549e+00,\n",
              "        2.9715e+00, 3.0178e+00, 3.1883e+00, 3.4648e+00, 3.8244e+00, 4.2459e+00,\n",
              "        4.7129e+00, 2.9890e+02, 7.4664e+01, 4.6626e+02, 3.6556e+02, 1.0106e+02,\n",
              "        8.1774e+01, 1.0620e+01, 1.4550e+01, 8.6549e+00, 1.1339e+01, 6.1655e+00,\n",
              "        6.1186e+00, 1.1634e+02, 1.5671e-01, 7.6579e-02, 1.0465e-01, 1.4141e-01,\n",
              "        1.7711e-01, 2.0979e-01, 2.0633e-01, 1.9011e-01, 2.1139e-01, 1.1458e-01,\n",
              "        3.8458e-02, 2.4806e-02, 8.2700e-02, 1.2448e-01, 1.0251e-01, 5.0011e-02,\n",
              "        3.3504e-01, 3.5840e-01, 3.2977e-01, 3.9313e-01, 3.4420e-01, 2.8032e-01,\n",
              "        3.2419e-01, 2.4276e-01, 3.7204e-01, 2.9687e-01, 4.4961e-01, 4.3487e-01,\n",
              "        6.3954e-01, 7.0986e-01, 8.0223e-01, 6.9994e-01, 7.1336e-01, 6.6738e-01,\n",
              "        6.3400e-01, 2.9345e-01, 2.8800e-01, 5.7916e-01, 6.8748e-01, 9.7445e-01,\n",
              "        1.3207e+00, 1.4521e+00, 1.6898e+00, 5.0067e-01, 6.0640e-01, 1.2042e+00,\n",
              "        1.2716e+00, 4.3339e-01, 4.2402e-01, 7.0819e-01], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyMtaT8yS1Li",
        "outputId": "3e0b0ba3-1cbc-4421-86f8-d281b5e57bc2"
      },
      "source": [
        "data_embed[:,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([389, 275, 100, 108, 318, 167, 196, 150, 196, 394, 295, 160, 747,\n",
              "       173, 148, 146, 144, 226, 678, 260, 423, 215, 182, 407, 133, 120,\n",
              "       101, 112, 2124, 147, 207, 150, 113, 106, 544, 154, 382, 2014, 371,\n",
              "       583, 800], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "478uGshX7oiL"
      },
      "source": [
        "# 1-Layer Fully Connected Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq1RmfFJf34j"
      },
      "source": [
        "## 10-Class Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbx2VCVif0fT"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "mean_train_error = 0\n",
        "mean_test_error = 0\n",
        "var_test_error = 0\n",
        "\n",
        "lr_decay = 0.8\n",
        "num_trials = 1\n",
        "learning_rate = 1e-3\n",
        "Num_updates = 20000\n",
        "losses = torch.zeros(num_trials, r-9, Num_updates)\n",
        "\n",
        "for s in range(num_trials):\n",
        "\n",
        "    error_train_list_all = []\n",
        "    error_test_list_all = []\n",
        "\n",
        "    Start_time_2 = time.time()\n",
        "\n",
        "    for i in range(r-9): \n",
        "\n",
        "        x = torch.cat((X_train[i], X_train[i+1], X_train[i+2], X_train[i+3], \n",
        "                       X_train[i+4],X_train[i+5], X_train[i+6], X_train[i+7],\n",
        "                       X_train[i+8], X_train[i+9]), 0).float()\n",
        "        y = torch.cat((0 * y_train[i], y_train[i+1], 2 * y_train[i+2], 3 * y_train[i+3],\n",
        "                       4 * y_train[i+4], 5 * y_train[i+5], 6 * y_train[i+6], 7* y_train[i+7],\n",
        "                       8 * y_train[i+8], 9 * y_train[i+9]), 0).long()\n",
        "\n",
        "        D_in = len(x[0]) # D_in is input dimension\n",
        "        H = 200 # H is the dimension of hidden layer\n",
        "        D_out = 10 # D_out is output dimension\n",
        "\n",
        "        model = torch.nn.Sequential(\n",
        "                                    torch.nn.Linear(D_in, H),\n",
        "                                    torch.nn.LeakyReLU(0.1),\n",
        "                                    #torch.nn.ReLU(),\n",
        "                                    #torch.nn.Tanh(),\n",
        "                                    #torch.nn.Dropout(p=q),\n",
        "                                    torch.nn.Linear(H, D_out)\n",
        "                                    )\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        \n",
        "        for t in range(Num_updates):\n",
        "            y_pred = model(x) # of shape (N,D_out)\n",
        "            #print(torch.argmax(y_pred, 1))\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            losses[s, i, t] = loss\n",
        "\n",
        "            #if t % 1000 == 0:\n",
        "            #    print(t, loss.item())\n",
        "                \n",
        "            if (t+1) % 1000 == 0:\n",
        "                optimizer.param_groups[0]['lr'] = lr_decay * learning_rate\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward() # Backward pass\n",
        "\n",
        "            optimizer.step()  # Calling the step function on the Optimizer \n",
        "\n",
        "        X = torch.cat((X_test[i], X_test[i+1], X_test[i+2], X_test[i+3], \n",
        "                       X_test[i+4],X_test[i+5], X_test[i+6], X_test[i+7],\n",
        "                       X_test[i+8], X_test[i+9]), 0).float()\n",
        "        Y = torch.cat((0 * y_test[i], y_test[i+1], 2 * y_test[i+2], 3 * y_test[i+3],\n",
        "                       4 * y_test[i+4], 5 * y_test[i+5], 6 * y_test[i+6], 7* y_test[i+7],\n",
        "                       8 * y_test[i+8], 9 * y_test[i+9]), 0).long()\n",
        "        \n",
        "        Y_pred = model(X)\n",
        "        \n",
        "        error_train_list_all.append((torch.argmax(y_pred, 1) != y).sum().float()/len(y))\n",
        "        error_test_list_all.append((torch.argmax(Y_pred, 1) != Y).sum().float()/len(Y))\n",
        "\n",
        "    mean_train_error += np.mean(error_train_list_all)\n",
        "    mean_test_error += np.mean(error_test_list_all)\n",
        "    var_test_error += np.var(error_test_list_all)\n",
        "\n",
        "mean_train_error /= num_trials\n",
        "mean_test_error /= num_trials\n",
        "var_test_error /= num_trials\n",
        "\n",
        "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv8zy2Myq1nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e82810-9c7d-478a-d127-9c07a2d3f559"
      },
      "source": [
        "print('|Q|=250,', 'Old Distance,', \"Number of Users: \", \"41,\", \n",
        "      'Number of Trials = ', num_trials)\n",
        "print(\"Activation function: LeakyReLU(0.01)\", \"Number of Updates = \", Num_updates)\n",
        "Dic_1 = {}\n",
        "\n",
        "Dic_1[1] = [\"FC 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
        "              np.round(mean_train_error, decimals = 4), \n",
        "              np.round(mean_test_error, decimals = 4),\n",
        "              np.round(var_test_error, decimals = 4)]\n",
        "    \n",
        "df_1 = pd.DataFrame.from_dict(Dic_1, \n",
        "                              orient='index', \n",
        "                              columns=['Classifier', 'Hid_dim', 'Drop Out p', \n",
        "                                       'L_Rate', 'Batch_Normaln', 'Train Error',\n",
        "                                       'Test Error', 'Var_Error'])\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=250, Old Distance, Number of Users:  41, Number of Trials =  1\n",
            "Activation function: LeakyReLU(0.01) Number of Updates =  20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hid_dim</th>\n",
              "      <th>Drop Out p</th>\n",
              "      <th>L_Rate</th>\n",
              "      <th>Batch_Normaln</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Var_Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FC 1-Layer</td>\n",
              "      <td>200</td>\n",
              "      <td>None</td>\n",
              "      <td>0.001</td>\n",
              "      <td>len(x)</td>\n",
              "      <td>0.3658</td>\n",
              "      <td>0.3816</td>\n",
              "      <td>0.0073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Classifier  Hid_dim Drop Out p  ...  Train Error Test Error  Var_Error\n",
              "1  FC 1-Layer      200       None  ...       0.3658     0.3816     0.0073\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvc6wAe2gQXf"
      },
      "source": [
        "## New Distance, $|Q|=250$, $\\sigma=1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "58hPp6vEgDOX",
        "outputId": "048dcbb2-a767-4d67-8035-02b959c99ad9"
      },
      "source": [
        "print('|Q|=250,', 'New Distance,', 'sigma=1', \"Number of Users: \", \"41,\", \n",
        "      'Number of Trials = ', num_trials)\n",
        "print(\"Activation function: LeakyReLU(0.01)\", \"Number of Updates = \", Num_updates)\n",
        "Dic_1 = {}\n",
        "\n",
        "Dic_1[1] = [\"FC 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
        "              np.round(mean_train_error, decimals = 4), \n",
        "              np.round(mean_test_error, decimals = 4),\n",
        "              np.round(var_test_error, decimals = 4)]\n",
        "    \n",
        "df_1 = pd.DataFrame.from_dict(Dic_1, \n",
        "                              orient='index', \n",
        "                              columns=['Classifier', 'Hid_dim', 'Drop Out p', \n",
        "                                       'L_Rate', 'Batch_Normaln', 'Train Error',\n",
        "                                       'Test Error', 'Var_Error'])\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=250, New Distance, sigma=1 Number of Users:  41, Number of Trials =  1\n",
            "Activation function: LeakyReLU(0.01) Number of Updates =  100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hid_dim</th>\n",
              "      <th>Drop Out p</th>\n",
              "      <th>L_Rate</th>\n",
              "      <th>Batch_Normaln</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Var_Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FC 1-Layer</td>\n",
              "      <td>200</td>\n",
              "      <td>None</td>\n",
              "      <td>0.01</td>\n",
              "      <td>len(x)</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.5646</td>\n",
              "      <td>0.0113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Classifier  Hid_dim Drop Out p  ...  Train Error Test Error  Var_Error\n",
              "1  FC 1-Layer      200       None  ...        0.078     0.5646     0.0113\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tugg4GNgVNV"
      },
      "source": [
        "## Old Distance, $|Q|=250$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "1k-PNFIRgEEK",
        "outputId": "168ddbdf-0a66-4374-f287-6c20a1cf7ae1"
      },
      "source": [
        "print('|Q|=250,', 'Old Distance,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
        "print(\"ReLU\", \"Number of Updates = \", Num_updates)\n",
        "Dic_1 = {}\n",
        "\n",
        "models = [\"Fully Connected 1-Layer\"]\n",
        "\n",
        "for k in range(len(models)): \n",
        "    Dic_1[k+1] = [models[k], H, learning_rate,  \n",
        "                  np.round(mean_train_error, decimals = 4), \n",
        "                  np.round(mean_test_error, decimals = 4),\n",
        "                  np.round(var_test_error, decimals = 4)]\n",
        "    \n",
        "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', columns=['Classifier', 'Hidden dim', \n",
        "                                                               'Learning Rate', 'Train Error', \n",
        "                                                              'Test Error', 'Variance Error'])\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=250, Old Distance, Number of Users:  41, Number of Trials =  1\n",
            "ReLU Number of Updates =  10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hidden dim</th>\n",
              "      <th>Learning Rate</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Variance Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fully Connected 1-Layer</td>\n",
              "      <td>200</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.4162</td>\n",
              "      <td>0.426</td>\n",
              "      <td>0.0096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Classifier  Hidden dim  ...  Test Error  Variance Error\n",
              "1  Fully Connected 1-Layer         200  ...       0.426          0.0096\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnI8nWyrf1eS"
      },
      "source": [
        "## Binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "m_aHl3VV7oiL",
        "outputId": "ea6afa2e-affe-4e26-d0c5-c708fb052c64"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "mean_train_error = 0\n",
        "mean_test_error = 0\n",
        "var_test_error = 0\n",
        "\n",
        "num_trials = 1\n",
        "Num_updates = 15000\n",
        "losses = torch.zeros(num_trials, r-1, Num_updates)\n",
        "learning_rate = 0.0008\n",
        "\n",
        "for s in range(num_trials):\n",
        "    \n",
        "    X_train_labeled = [0] * r\n",
        "    X_test_labeled = [0] * r\n",
        "    error_train_list_all = []\n",
        "    error_test_list_all = []\n",
        "\n",
        "    Start_time_2 = time.time()\n",
        "\n",
        "    for i in range(r-1): \n",
        "        j = i+1\n",
        "\n",
        "        x = torch.cat((X_train[i], X_train[j]), 0).float()\n",
        "        y = torch.cat((y_train[i], \n",
        "                       torch.zeros(y_train[j].size(), dtype=torch.double)), 0).long()\n",
        "\n",
        "        N = len(x) # N is batch size\n",
        "        D_in = len(x[0]) # D_in is input dimension\n",
        "        H = 100 # H is the hidden dimension \n",
        "        D_out = 2 # D_out is output dimension\n",
        "        q = 0.25\n",
        "\n",
        "        model = torch.nn.Sequential(\n",
        "                                    torch.nn.Linear(D_in, H),\n",
        "                                    torch.nn.LeakyReLU(0.01),\n",
        "                                    #torch.nn.Tanh(),\n",
        "                                    #torch.nn.ReLU(),\n",
        "                                    #torch.nn.Dropout(p=q),\n",
        "                                    torch.nn.Linear(H, D_out)\n",
        "                                    )\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        \n",
        "        for t in range(Num_updates):\n",
        "            y_pred = model(x) # of shape (N,D_out)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            losses[s, i, t] = loss\n",
        "\n",
        "            #if t % 499 == 498:\n",
        "            #    print(t, loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward() # Backward pass\n",
        "\n",
        "            optimizer.step()  # Calling the step function on the Optimizer \n",
        "\n",
        "        X = torch.cat((X_test[i], X_test[j]), 0).float()\n",
        "        Y = torch.cat((y_test[i], torch.zeros(y_test[j].size(), \n",
        "                                              dtype=torch.double)), 0).long()\n",
        "        Y_pred = model(X)\n",
        "\n",
        "        error_train_list_all.append(int(sum(abs(torch.argmax(y_pred, axis=1)-y)))/y.shape[0])\n",
        "        error_test_list_all.append(int(sum(abs(torch.argmax(Y_pred, axis=1)-Y)))/Y.shape[0])\n",
        "\n",
        "    mean_train_error += np.mean(error_train_list_all)\n",
        "    mean_test_error += np.mean(error_test_list_all)\n",
        "    var_test_error += np.var(error_test_list_all)\n",
        "\n",
        "mean_train_error /= num_trials\n",
        "mean_test_error /= num_trials\n",
        "var_test_error /= num_trials\n",
        "\n",
        "plt.plot((torch.mean(losses[0], dim=0)).detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGlaPJ2W9uNU"
      },
      "source": [
        "## New Distance, $|Q|=250$, $\\sigma=1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "wLV3A_WXnuah",
        "outputId": "6dfebdad-3528-4637-bafa-927367b09508"
      },
      "source": [
        "print('|Q|=250,', 'New Distance,', 'sigma=1', \"Number of Users: \", \"41,\", \n",
        "      'Number of Trials = ', num_trials)\n",
        "print(\"Activation function: ReLU\", \"Number of Updates = \", Num_updates)\n",
        "Dic_1 = {}\n",
        "\n",
        "Dic_1[1] = [\"FC 1-Layer\", H, None, learning_rate, \"len(x)\", \n",
        "              np.round(mean_train_error, decimals = 4), \n",
        "              np.round(mean_test_error, decimals = 4),\n",
        "              np.round(var_test_error, decimals = 4)]\n",
        "    \n",
        "df_1 = pd.DataFrame.from_dict(Dic_1, \n",
        "                              orient='index', \n",
        "                              columns=['Classifier', 'Hid_dim', 'Drop Out p', \n",
        "                                       'L_Rate', 'Batch_Normaln', 'Train Error',\n",
        "                                       'Test Error', 'Var_Error'])\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=250, New Distance, sigma=1 Number of Users:  41, Number of Trials =  1\n",
            "Activation function: ReLU Number of Updates =  1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hid_dim</th>\n",
              "      <th>Drop Out p</th>\n",
              "      <th>L_Rate</th>\n",
              "      <th>Batch_Normaln</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Var_Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FC 1-Layer</td>\n",
              "      <td>10</td>\n",
              "      <td>None</td>\n",
              "      <td>0.01</td>\n",
              "      <td>len(x)</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.2667</td>\n",
              "      <td>0.0094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Classifier  Hid_dim Drop Out p  ...  Train Error Test Error  Var_Error\n",
              "1  FC 1-Layer       10       None  ...       0.0078     0.2667     0.0094\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkY9PI4n85e_"
      },
      "source": [
        "## Old Distance, $|Q|=250$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "88tEFGCfu6D7",
        "outputId": "d196e0b1-f271-4079-af7f-ab9cbb795c29"
      },
      "source": [
        "print('|Q|=250,', 'Old Distance,', \"Number of Users: \", \"41,\", 'Number of Trials = ', num_trials)\n",
        "print(\"ReLU\", \"Number of Updates = \", Num_updates)\n",
        "Dic_1 = {}\n",
        "\n",
        "models = [\"Fully Connected 1-Layer\"]\n",
        "\n",
        "for k in range(len(models)): \n",
        "    Dic_1[k+1] = [models[k], H[0], None, learning_rate, \"len(x)\", \n",
        "                  np.round(mean_train_error, decimals = 4), \n",
        "                  np.round(mean_test_error, decimals = 4),\n",
        "                  np.round(var_test_error, decimals = 4)]\n",
        "    \n",
        "df_1 = pd.DataFrame.from_dict(Dic_1, orient='index', columns=['Classifier', 'Hidden dim', \n",
        "                                                              'Drop Out p', 'Learning Rate',\n",
        "                                                              'Batch Normalization', 'Train Error', \n",
        "                                                              'Test Error', 'Variance Error'])\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=250, Old Distance, Number of Users:  41, Number of Trials =  1\n",
            "ReLU Number of Updates =  15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hidden dim</th>\n",
              "      <th>Drop Out p</th>\n",
              "      <th>Learning Rate</th>\n",
              "      <th>Batch Normalization</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Variance Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fully Connected 1-Layer</td>\n",
              "      <td>100</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>len(x)</td>\n",
              "      <td>0.0827</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>0.0078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Classifier  Hidden dim  ... Test Error  Variance Error\n",
              "1  Fully Connected 1-Layer         100  ...     0.0965          0.0078\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLjrC4vsTJiF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}